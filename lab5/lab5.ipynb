{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eaaf645",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import regex\n",
    "import time\n",
    "from collections import defaultdict, Counter\n",
    "import math\n",
    "import requests\n",
    "import itertools\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e897f51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_archive(path):\n",
    "    tar = tarfile.open(path, \"r:gz\")   \n",
    "    files = {}\n",
    "    for filename in tar.getnames():\n",
    "        f = tar.extractfile(filename)\n",
    "        files[filename] = f.read().decode(\"utf-8\").replace('\\n', ' ').replace('\\t', ' ').lower()\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d11e753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = read_archive('./ustawy.tar.gz')\n",
    "type(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3adf23",
   "metadata": {},
   "source": [
    "# 1. Download docker image of KRNNT2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0242cedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ala\tnone\n",
      "\tAla\tsubst:sg:nom:f\tdisamb\n",
      "ma\tspace\n",
      "\tmieć\tfin:sg:ter:imperf\tdisamb\n",
      "kota\tspace\n",
      "\tkot\tsubst:sg:acc:m2\tdisamb\n",
      ".\tnone\n",
      "\t.\tinterp\tdisamb\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(requests.post('http://krnnt:9200', data='Ala ma kota.').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74af50e9",
   "metadata": {},
   "source": [
    "# 3. Use the tool to tag and lemmatize the law corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6126a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_bill(bill_content):\n",
    "    lemmatized = requests.post('http://krnnt:9200', data=bill_content.encode('utf-8')).text\n",
    "    res = [l for l in lemmatized.split('\\n') if l != '']\n",
    "    result = []\n",
    "    for w, e in zip(res[0::2], res[1::2]):\n",
    "        _, token, category, _ = e.split('\\t')\n",
    "        result.append((token, category.split(':')[0]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2e48bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lematized_bills = {filename:lemmatize_bill(content) for filename, content in list(files.items())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19ee72f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save():\n",
    "    import pickle\n",
    "    with open('lematized.pck', 'wb') as f:\n",
    "        pickle.dump(lematized_bills, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58f83ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1991719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load():\n",
    "    import pickle\n",
    "    with open('lematized.pck', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5df6dc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1179\n"
     ]
    }
   ],
   "source": [
    "print(len(lematized_bills))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e6f87c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dziennik brev\n",
      ". interp\n",
      "u prep\n",
      ". interp\n",
      "z prep\n",
      "1993 adj\n",
      "rok brev\n",
      ". interp\n",
      "numer brev\n",
      "129 num\n"
     ]
    }
   ],
   "source": [
    "for token, category in lematized_bills[list(lematized_bills.keys())[1]][:10]:\n",
    "    print(token, category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b03472",
   "metadata": {},
   "source": [
    "# 4. Using the tagged corpus compute bigram statistic for the tokens containing:\n",
    "- lemmatized, downcased word\n",
    "- morphosyntactic category of the word (subst, fin, adj, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b25e60f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(lemmatized_acts, n):\n",
    "    grams = []\n",
    "    for act in lemmatized_acts:\n",
    "        for i in range(len(act) - n + 1):\n",
    "            my_gram = []\n",
    "            for tok, category in act[i:i+n]:\n",
    "                lower_word = tok.lower()\n",
    "                my_gram.append( (lower_word, category) )\n",
    "            \n",
    "            grams.append(tuple(my_gram))\n",
    "    return grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50211479",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = get_ngrams(lematized_bills.values(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6ff5bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = Counter(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b72cb30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((('artykuł', 'brev'), ('.', 'interp')), 83645),\n",
       " ((('ustęp', 'brev'), ('.', 'interp')), 53345),\n",
       " ((('pozycja', 'brev'), ('.', 'interp')), 45081),\n",
       " (((',', 'interp'), ('pozycja', 'brev')), 43033),\n",
       " ((('.', 'interp'), ('1', 'adj')), 39939),\n",
       " ((('-', 'interp'), ('-', 'interp')), 36548),\n",
       " ((('rok', 'brev'), ('.', 'interp')), 33025),\n",
       " ((('w', 'prep'), ('artykuł', 'brev')), 31973),\n",
       " (((',', 'interp'), ('o', 'prep')), 29920),\n",
       " ((('o', 'prep'), ('który', 'adj')), 28656)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85621e4",
   "metadata": {},
   "source": [
    "# 5. Discard bigrams containing characters other than letters. Make sure that you discard the invalid entries after computing the bigram counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "560d508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = Counter({\n",
    "    key: cnt for key, cnt in bigrams.items() if all(\n",
    "        w[0].isalpha() for w in key\n",
    "    ) \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1e3148d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((('w', 'prep'), ('artykuł', 'brev')), 31973),\n",
       " ((('o', 'prep'), ('który', 'adj')), 28656),\n",
       " ((('który', 'adj'), ('mowa', 'subst')), 28538),\n",
       " ((('mowa', 'subst'), ('w', 'prep')), 28473),\n",
       " ((('w', 'prep'), ('ustęp', 'brev')), 23500),\n",
       " ((('z', 'prep'), ('dzień', 'subst')), 11360),\n",
       " ((('otrzymywać', 'fin'), ('brzmienie', 'subst')), 10533),\n",
       " ((('określić', 'ppas'), ('w', 'prep')), 9689),\n",
       " ((('do', 'prep'), ('sprawa', 'subst')), 8718),\n",
       " ((('ustawa', 'subst'), ('z', 'prep')), 8625)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177617ad",
   "metadata": {},
   "source": [
    "# 7. Compute LLR statistic for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9eac1342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormEntropy(counts):\n",
    "    '''Computes the entropy of a list of counts scaled by the sum of the counts. If the inputs sum to one, this is just the normal definition of entropy'''\n",
    "    counts = list(counts)\n",
    "    total = float(sum(counts))\n",
    "    # Note tricky way to avoid 0*log(0)\n",
    "    return -sum([k * math.log(k/total + (k==0)) for k in counts])\n",
    "\n",
    "def llr_2x2(k11, k12, k21, k22):\n",
    "    '''Special case of llr with a 2x2 table'''\n",
    "    return 2 * (denormEntropy([k11+k12, k21+k22]) +\n",
    "                denormEntropy([k11+k21, k12+k22]) -\n",
    "                denormEntropy([k11, k12, k21, k22]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4b251a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_count_word_a = defaultdict(int)\n",
    "bigrams_count_word_b = defaultdict(int)\n",
    "\n",
    "for (word_a, word_b), cnt in bigrams.items():\n",
    "    bigrams_count_word_a[word_a] += cnt\n",
    "    bigrams_count_word_b[word_b] += cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bae88be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_bigrams = sum(bigrams.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "053822be",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_llr = dict()\n",
    "for (word_a, word_b), cnt in bigrams.items():\n",
    "    k11 = cnt\n",
    "    k12 = bigrams_count_word_b[word_b] - cnt\n",
    "    k21 = bigrams_count_word_a[word_a] - cnt\n",
    "    k22 = total_bigrams - (k12 + k21 + k11)\n",
    "    bigrams_llr[(word_a, word_b)] = (llr_2x2(k11, k12, k21, k22), cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd365de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_llr_sorted = sorted(bigrams_llr.items(), key = lambda x: -x[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b23dd9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "który:adj            mowa:subst         : 248052.7143701301\n",
      "--------------------------------------------------------------------------------\n",
      "o:prep               który:adj          : 190483.81637835805\n",
      "--------------------------------------------------------------------------------\n",
      "mowa:subst           w:prep             : 177052.40660559037\n",
      "--------------------------------------------------------------------------------\n",
      "w:prep               artykuł:brev       : 113594.38314276375\n",
      "--------------------------------------------------------------------------------\n",
      "otrzymywać:fin       brzmienie:subst    : 110710.45626359055\n",
      "--------------------------------------------------------------------------------\n",
      "w:prep               ustęp:brev         : 87868.61976416851\n",
      "--------------------------------------------------------------------------------\n",
      "minister:subst       właściwy:adj       : 70827.04352484498\n",
      "--------------------------------------------------------------------------------\n",
      "dodawać:fin          się:qub            : 66615.98127911263\n",
      "--------------------------------------------------------------------------------\n",
      "i:conj               numer:brev         : 54297.893606414786\n",
      "--------------------------------------------------------------------------------\n",
      "droga:subst          rozporządzenie:subst: 54022.582674282894\n"
     ]
    }
   ],
   "source": [
    "for ((text1, cat1), (text2, cat2)), (llr, occ) in bigrams_llr_sorted[:10]:\n",
    "    pair = text1 +':'+cat1\n",
    "    text = f'{pair:<20} {text2}:{cat2}'\n",
    "    print('-'*80)\n",
    "    print(f'{text:<40}: {llr}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65c9336",
   "metadata": {},
   "source": [
    "# 8. Partition the entries based on the syntactic categories of the words, i.e. all bigrams having the form of w1:adj w2:subst should be placed in one partition (the order of the words may not be changed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2bfd1d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_grouped = defaultdict(list)\n",
    "\n",
    "for ((text1, cat1), (text2, cat2)), (llr, occ) in bigrams_llr_sorted:\n",
    "    bigrams_grouped[(cat1, cat2)].append( (text1, text2, llr, occ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee1e1b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adj subst\n",
      "\t- który mowa\n",
      "\t- niniejszy ustawa\n",
      "\t- następujący zmiana\n",
      "\t- odrębny przepis\n",
      "\t- walny zgromadzenie\n",
      "\t- członkowski unia\n",
      "\t- szczegółowy zasada\n",
      "\t- główny inspektor\n",
      "\t- wojewódzki inspektor\n",
      "\t- państwowy straż\n"
     ]
    }
   ],
   "source": [
    "for (cat1, cat2), list_of_tokens in bigrams_grouped.items():\n",
    "    header = f'{cat1} {cat2}'\n",
    "    \n",
    "    words = [f'\\t- {t[0]} {t[1]}' for t in list_of_tokens[:10]]\n",
    "    words = '\\n'.join(words)\n",
    "    text = f'{header}\\n{words}'\n",
    "    print(text)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47b2869",
   "metadata": {},
   "source": [
    "# 9. Select the 10 largest partitions (partitions with the largest number of entries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c4e9652",
   "metadata": {},
   "outputs": [],
   "source": [
    "biggest_bigrams = list(sorted(\n",
    "    bigrams_grouped.items(),\n",
    "    key=lambda x: -sum(map(lambda t: t[3], x[1]))\n",
    "))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1dbf761d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prep:subst           323531\n",
      "subst:subst          280155\n",
      "subst:adj            273728\n",
      "adj:subst            188423\n",
      "subst:prep           170971\n",
      "subst:conj           84085\n",
      "conj:subst           83077\n",
      "ger:subst            81373\n",
      "prep:adj             79705\n",
      "prep:brev            66969\n"
     ]
    }
   ],
   "source": [
    "for (cat1, cat2), list_of_tokens in biggest_bigrams:\n",
    "    text = f'{cat1}:{cat2}'\n",
    "    sum_occ = sum(map(lambda x: x[3], list_of_tokens))\n",
    "    print(f'{text:20} {sum_occ}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43da5c9",
   "metadata": {},
   "source": [
    "# 10. Use the computed LLR measure to select 5 bigrams for each of the largest categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c2ed8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_top_5(bigrams_list):\n",
    "    result = []\n",
    "    for (cat1, cat2), list_of_tokens in bigrams_list:\n",
    "        result.append(((cat1, cat2), list_of_tokens[:5]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61d52766",
   "metadata": {},
   "outputs": [],
   "source": [
    "biggest_bigrams = select_top_5(biggest_bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef01320e",
   "metadata": {},
   "source": [
    "Let's print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7d986c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_bigrams(bigram_list):\n",
    "    for (cat1, cat2), list_of_tokens in bigram_list:\n",
    "        print('-'*80)\n",
    "        header = f'{cat1} {cat2}'\n",
    "        \n",
    "        toks = [(t[0] + ' ' + t[1], t[2]) for t in list_of_tokens]\n",
    "\n",
    "        words = [f'\\t- {t[0]:<30}: {t[1]}' for t in toks]\n",
    "        words = '\\n'.join(words)\n",
    "        text = f'{header}\\n{words}'\n",
    "\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4907a8",
   "metadata": {},
   "source": [
    "By the number of bigrams first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "031a98ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "prep subst\n",
      "\t- z dzień                       : 53443.161432914436\n",
      "\t- na podstawa                   : 47039.98370506626\n",
      "\t- do sprawa                     : 46293.95840313053\n",
      "\t- w droga                       : 31998.72346495255\n",
      "\t- od dzień                      : 31547.64117067482\n",
      "--------------------------------------------------------------------------------\n",
      "subst subst\n",
      "\t- droga rozporządzenie          : 54022.582674282894\n",
      "\t- skarb państwo                 : 22069.276876578064\n",
      "\t- rada minister                 : 18278.401483014226\n",
      "\t- terytorium rzeczpospolita     : 14071.448988002143\n",
      "\t- ochrona środowisko            : 14016.563116224948\n",
      "--------------------------------------------------------------------------------\n",
      "subst adj\n",
      "\t- minister właściwy             : 70827.04352484498\n",
      "\t- rzeczpospolita polski         : 46132.30327139744\n",
      "\t- jednostka organizacyjny       : 24498.74647179988\n",
      "\t- samorząd terytorialny         : 23434.66083263346\n",
      "\t- produkt leczniczy             : 21897.874760452105\n",
      "--------------------------------------------------------------------------------\n",
      "adj subst\n",
      "\t- który mowa                    : 248052.7143701301\n",
      "\t- niniejszy ustawa              : 21432.65664697066\n",
      "\t- następujący zmiana            : 20429.34032337078\n",
      "\t- odrębny przepis               : 12944.735959815414\n",
      "\t- walny zgromadzenie            : 9462.504395598826\n",
      "--------------------------------------------------------------------------------\n",
      "subst prep\n",
      "\t- mowa w                        : 177052.40660559037\n",
      "\t- ustawa z                      : 41881.52535883989\n",
      "\t- wniosek o                     : 15403.27247752191\n",
      "\t- dzień od                      : 13909.888261494518\n",
      "\t- miesiąc od                    : 12300.317582178774\n",
      "--------------------------------------------------------------------------------\n",
      "subst conj\n",
      "\t- przecinek i                   : 3941.63847658562\n",
      "\t- wolność albo                  : 2268.2375855262508\n",
      "\t- imię i                        : 2194.071625678218\n",
      "\t- całość lub                    : 2163.767667472537\n",
      "\t- zasada i                      : 1904.2505976171233\n",
      "--------------------------------------------------------------------------------\n",
      "conj subst\n",
      "\t- i tryb                        : 4689.061877883272\n",
      "\t- i nazwisko                    : 2524.90154491039\n",
      "\t- i usługa                      : 1873.575164685375\n",
      "\t- i adres                       : 1733.490032881964\n",
      "\t- oraz sposób                   : 1456.060395611683\n",
      "--------------------------------------------------------------------------------\n",
      "ger subst\n",
      "\t- pozbawić wolność              : 14596.881039931293\n",
      "\t- zasięgnąć opinia              : 11520.451075743294\n",
      "\t- wykonywać zawód               : 5546.142674478804\n",
      "\t- zawrzeć umowa                 : 5232.311856187909\n",
      "\t- wszcząć postępowanie          : 5147.228779848752\n",
      "--------------------------------------------------------------------------------\n",
      "prep adj\n",
      "\t- o który                       : 190483.81637835805\n",
      "\t- w ten                         : 1365.6821260277648\n",
      "\t- za każdy                      : 1363.7125321549538\n",
      "\t- w właściwy                    : 1285.7847912369762\n",
      "\t- przez ten                     : 1070.6434916114085\n",
      "--------------------------------------------------------------------------------\n",
      "prep brev\n",
      "\t- w artykuł                     : 113594.38314276375\n",
      "\t- w ustęp                       : 87868.61976416851\n",
      "\t- w punkt                       : 11000.112371308263\n",
      "\t- z późniejszy                  : 7823.761158948764\n",
      "\t- w dziennik                    : 4648.895240809303\n"
     ]
    }
   ],
   "source": [
    "print_bigrams(biggest_bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9054ec",
   "metadata": {},
   "source": [
    "And now by the count of bigrams:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a905b0",
   "metadata": {},
   "source": [
    "# 11. Using the results from the previous step answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca33e955",
   "metadata": {},
   "source": [
    "## a. What types of bigrams have been found?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b0fb6c",
   "metadata": {},
   "source": [
    "The most of bigrams contains a noun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9c7fcb",
   "metadata": {},
   "source": [
    "## b. Which of the category-pairs indicate valuable multiword expressions? Do they have anything in common?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dea108",
   "metadata": {},
   "source": [
    "noun + noun and noun + adjective (eg. `minister finanse`, `rachunek bankowy`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da476966",
   "metadata": {},
   "source": [
    "## c. Which signal: LLR score or syntactic category is more useful for determining genuine multiword expressions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c1ce8b",
   "metadata": {},
   "source": [
    "LLR score used on filtered category from point b."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1c6e1b",
   "metadata": {},
   "source": [
    "## d. Can you describe a different use-case where the morphosyntactic category is useful for resolving a real-world problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ea777f",
   "metadata": {},
   "source": [
    "- Keywords:\n",
    "\n",
    "We can grab the most common nouns in text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d1a2ab",
   "metadata": {},
   "source": [
    "- More inteligent corrections of word\n",
    "\n",
    "If we know the category we can provide better correction proposotions\n",
    "\n",
    "- Extracting meaning from text\n",
    "\n",
    "For example extracting subject of sentence when analyzing text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd81d489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852616e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bf4a85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
